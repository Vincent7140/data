import numpy as np
import tensorflow as tf
import imageio
import matplotlib.pyplot as plt
from io import BytesIO
from PIL import Image
from data_handling import pose_spherical

def render_views_to_video(model, arg_dict, hwf, azimuths, elevations, radius, zoom_factor=1.0, rets=['rgb'], fps=10, output_path='output_video.mp4'):
    """
    G√©n√®re une vid√©o MP4 annot√©e √† partir des rendus S-NeRF.
    """
    frames = []

    for i, (az_deg, el_deg) in enumerate(zip(azimuths, elevations)):
        az = np.deg2rad(az_deg)
        el = np.deg2rad(el_deg)

        pose = pose_spherical(az, el, radius)
        view_dir = tf.reshape(tf.convert_to_tensor([az, el], dtype=tf.float32), [1,2])
        light_dir = tf.reshape(tf.convert_to_tensor([az, el], dtype=tf.float32), [1,2])

        result = render_image(model, arg_dict, hwf, pose, zoom_factor, light_dir, view_dir, rets)
        rgb_image = (255 * result["rgb"].numpy()).astype(np.uint8)

        # Ajout de texte via matplotlib
        fig, ax = plt.subplots(figsize=(6, 6))
        ax.imshow(rgb_image)
        ax.axis('off')
        annotation = f"Az: {az_deg:.1f}¬∞, El: {el_deg:.1f}¬∞, R: {radius:.1f}"
        ax.text(0.98, 0.02, annotation, fontsize=12, color='white',
                ha='right', va='bottom', transform=ax.transAxes,
                bbox=dict(facecolor='black', alpha=0.6, boxstyle='round,pad=0.3'))

        # Convertir figure matplotlib ‚Üí image numpy avec PIL
        buf = BytesIO()
        plt.savefig(buf, format='png')
        buf.seek(0)
        pil_img = Image.open(buf).convert("RGB")
        frames.append(np.array(pil_img))
        plt.close(fig)

    # Sauvegarde vid√©o
    imageio.mimwrite(output_path, frames, fps=fps, quality=8)
    print(f"üé• Vid√©o g√©n√©r√©e : {output_path}")
